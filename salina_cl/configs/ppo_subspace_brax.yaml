name: ppo_subspace
seed: 0
save_model: True
final_evaluation: False
perf_path: /checkpoint/jbgaya/CRL_subspace/multirun/${scenario.name}/${name}/${now:%Y-%m-%d_%H-%M-%S}/perf_per_experiment.dat


defaults: 
  - logger: logger
  - scenario: halfcheetah_debug
  - algorithm: ppo
  - hydra: hydra
  - evaluation: evaluation_subspace
  - override hydra/launcher: submitit_slurm


model:
  classname: salina_cl.models.subspace.TwoSteps
  seed: ${seed}
  params:
    evaluation:
      device: cuda:0
      seed: 1
      n_rollouts: 1
      scale: 89 #For building the triangle
      steps: 4096
      evaluate_success: False

    algorithm0:
      classname: salina_cl.algorithms.anchor_init.anchor_init
      params:
        n_processes: 0
        acquisition_device: cuda:0
        k: 512
        n_envs: ${scenario.n_train_envs}
        budget: 0.

    algorithm1: ${algorithm}
    lr_scaling:  0.5 #scaling of the lr * nb_anchors
    
    algorithm2:
      classname: salina_cl.algorithms.value_estimation_2.value_estimation
      params:
        device: cuda:0
        steps: 4096
        scale: 89
        threshold: 0.

    policy_agent:
      classname: salina_cl.agents.subspace_agents.SubspaceActionAgent
      hidden_size: 64
      n_layers: 4
      input_dimension: nil
      output_dimension: nil

      n_initial_anchors: 1
      dist_type: flat
      refresh_rate: 1.

    critic_agent:
      classname: salina_cl.agents.subspace_agents.CriticAgent
      hidden_size: 256
      n_layers: 4
      input_dimension: nil
      n_anchors:
