classname: salina_cl.algorithms.ppo.ppo
params:
  learning_device: cuda:0
  acquisition_device: cuda:0

  optimizer_policy:
    classname: torch.optim.Adam
    lr: [0.0003,0.001]

  optimizer_critic:
    classname: torch.optim.Adam
    lr: [0.0003,0.001]

  clip_grad: 10.0

  control_every_n_epochs: 10
  n_control_rollouts: 0
  n_timesteps: 100                 # rollout length before each epoch
  n_processes: 0 
  n_minibatches: [64,128]           # nb of minibatches per epoch
  n_envs_per_minibatch: 512             # sample size of each minibatch
  n_timesteps_per_minibatch: [20,50]  # timestep size of each minibatch
  n_times_per_minibatch: 1
  policy_update_delay: [4,8]         # control the frequency of the policy update
  discount_factor: 0.99
  clip_ratio: 0.3
  action_std: 0.4
  gae: 0.96
  reward_scaling: 1.
  time_limit: 0