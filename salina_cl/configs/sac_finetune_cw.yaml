name: sac_finetune
seed: 0
perf_path: results/test.dat
save_model: False
final_evaluation: False

defaults:
  - logger: logger
  - scenario: cw3
  - hydra: hydra
  - evaluation: evaluation_subspace
  - override hydra/launcher: submitit_slurm

model:
  classname: salina_cl.models.models.Baseline
  seed: ${seed}
  params:
    checkpoint: True
    evaluation:
      device: cpu
      seed: ${seed}
      n_rollouts: 5
      evaluate_success: False
    reset_critic_on_task_change: False
    algorithm:
      classname: salina_cl.algorithms.sac.sac
      params:
        learning_device: cuda:0
        acquisition_device: cpu
        buffer_device: cuda:0
    
        optimizer_policy:
          classname: torch.optim.Adam
          lr: 1e-3
    
        optimizer_q:
          classname: torch.optim.Adam
          lr: 1e-3

        optimizer_entropy:
          classname: torch.optim.Adam
          lr: 1e-3
    
        control_every_n_epochs: 100
        n_control_rollouts: 1
      
        n_processes: 0
  
        reward_scaling: 1.
        policy_update_delay: 2
        target_update_delay: 2
        time_limit: 0
        
        n_timesteps: 25  ## burning timesteps
        batch_size: 128   ## 128 ,256,512

        init_temperature: 2.7
        target_multiplier: 2.
       
        clip_grad: 50.
        inner_epochs: 50
        grad_updates_per_step: 1.
        discount_factor: 0.99
        update_target_tau: 0.005
        buffer_time_size: 2
        buffer_size: 1_000_000
        initial_buffer_size: 1_000

    policy_agent:
      classname: salina_cl.agents.single_agents_sac.MultiActionAgent
      hidden_size: 256
      input_dimension: nil
      output_dimension: nil
      start_steps: 10_000
      layer_norm: True

    critic_agent:
      classname: salina_cl.agents.single_agents_sac.TwinCritics
      hidden_size: 256
      obs_dimension: nil
      action_dimension: nil