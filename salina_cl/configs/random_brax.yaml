name: random
seed: 0

defaults:
  - logger: logger
  - override hydra/launcher: submitit_slurm

scenario:
  classname: salina_cl.scenarios.brax.halfcheetah.halfcheetah_hard
  name: halfcheetah_hard
  n_train_envs: 512
  n_evaluation_envs: 512
  n_steps: 0

model:
  classname: salina_cl.models.single.FineTune
  seed: ${seed}
  params:
    evaluation:
      device: cuda:0
      seed: ${seed}
      n_rollouts: 1
      evaluate_success: False

    algorithm: 
      classname: salina_cl.algorithms.ppo.ppo
      params:
        learning_device: cuda:0
        acquisition_device: cuda:0

        optimizer_policy:
          classname: torch.optim.Adam
          lr: 0.0003

        optimizer_critic:
          classname: torch.optim.Adam
          lr: 0.0003

        clip_grad: 10.0

        control_every_n_epochs: 10
        n_control_rollouts: 0
        n_timesteps: 50
        n_processes: 0
        n_minibatches: 64
        n_envs_per_minibatch: 512
        n_timesteps_per_minibatch: 10
        n_times_per_minibatch: 1

        discount_factor: 0.99
        clip_ratio: 0.2
        action_std: 0.4
        gae: 0.96
        reward_scaling: 1.0

        time_limit: 0
  
    policy_agent:
      classname: salina_cl.agents.single_agents.IncrementalBatchNormActionAgent
      hidden_size: 64
      n_layers: 4
      input_dimension: nil
      output_dimension: nil

    critic_agent:
      classname: salina_cl.agents.single_agents.CriticAgent
      hidden_size: 256
      n_layers: 4
      input_dimension: nil

hydra:
  run:
    dir: results/run/${scenario.name}/${name}/${hydra.job.override_dirname}/seed=${seed}
  sweep:
    dir: results/multirun/${scenario.name}/${name}/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    env_set:
      OMP_NUM_THREADS: '1'
      XLA_PYTHON_CLIENT_PREALLOCATE: 'false'
    config:
      override_dirname:
        item_sep: /
        exclude_keys:
          - seed
  launcher:
    mem_gb: 16
    max_num_timeout: 0
    cpus_per_task: 1
    signal_delay_s: 30
    timeout_min: 30
    gpus_per_node: 1
    tasks_per_node: 1
    partition: learnlab
    comment: CoLLa2022
  job_logging:
    root:
      handlers: []