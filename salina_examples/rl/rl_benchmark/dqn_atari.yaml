logger:
  classname: salina.logger.TFLogger
  log_dir: ./ddqn_atari
  modulo: 100
  every_n_seconds: 60
  verbose: False

n_envs: 1
n_processes: 1
loss_device: cuda:0

q_agent:
  classname: salina_examples.rl.dqn.agents.DQNAtariAgent
  env: ${env}

algorithm:
  env: ${env}

  env_seed: 432
  batch_size: 64
  max_epoch: 100000000

  optimizer:
    classname: torch.optim.Adam
    lr: 0.0001

  epsilon_start: 1.0
  epsilon_final: 0.01
  epsilon_exploration_decay: 30000
  burning_timesteps: 0
  clip_grad: 2
  inner_epochs: ${n_timesteps}
  discount_factor: 0.99
  hard_target_update: True
  update_target_epochs: 1000
  update_target_tau: 0.005
  loss_device: ${loss_device}
  n_envs: ${n_envs}
  n_processes: ${n_processes}
  n_timesteps: 2
  overlapping_timesteps: 1
  buffer_size: 100000
  initial_buffer_size: 10000
  buffer_time_size: 2

hydra:
  launcher:
    nodes: 1
    mem_gb: 64
    max_num_timeout: 0
    cpus_per_task: ${plus:${n_processes},1}
    signal_delay_s: 30
    timeout_min: 180
    gpus_per_node: ${n_gpus:${loss_device}}
    tasks_per_node: 1
    partition: learnfair
  job_logging:
    root:
      handlers: []

defaults:
  - hydra/launcher: submitit_slurm
