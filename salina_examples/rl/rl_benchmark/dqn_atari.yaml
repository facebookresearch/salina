logger:
  classname: salina.logger.TFLogger
  log_dir: ./dqn_atari
  modulo: 100
  every_n_seconds: 60
  verbose: True

q_agent:
  classname: salina_examples.rl.dqn.agents.DQNAtariAgent
  env: ${env}

algorithm:
  env: ${env}

  env_seed: 432
  batch_size: 64
  max_epoch: 100000000

  optimizer:
    classname: torch.optim.Adam
    lr: 0.0001

  epsilon_start: 1.0
  epsilon_final: 0.01
  epsilon_exploration_decay: 30000
  burning_timesteps: 0
  clip_grad: 2
  inner_epochs: 16
  discount_factor: 0.99
  hard_target_update: True
  update_target_epochs: 1000
  update_target_tau: 0.005
  loss_device: cpu
  n_envs: 16
  n_processes: 4
  n_timesteps: 2
  overlapping_timesteps: 1
  buffer_size: 100000
  initial_buffer_size: 10000
  buffer_time_size: 2

hydra:
  launcher:
    nodes: 1
    mem_gb: 64
    max_num_timeout: 0
    signal_delay_s: 30
    timeout_min: 180
    cpus_per_task: ${plus:${algorithm.n_processes},1}
    gpus_per_node: ${n_gpus:${algorithm.loss_device}}
    tasks_per_node: 1
    partition: learnfair
  job_logging:
    root:
      handlers: []

defaults:
  - hydra/launcher: submitit_slurm
  - env: gym_cartpole
