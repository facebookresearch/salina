logger:
  classname: salina.logger.TFLogger
  log_dir: ./ddqn
  modulo: 100
  every_n_seconds: 300
  verbose: False

n_envs: 1
env_name: PongNoFrameskip-v4
n_timesteps: 2

q_agent:
  classname: salina_examples.rl.dqn.agents.DQNAtariAgent
  env:
    classname: salina_examples.rl.dqn.agents.make_atari_env
    env_name: ${env_name}
    max_episode_steps: 100000

algorithm:
  env:
    classname: salina_examples.rl.dqn.agents.make_atari_env
    env_name: ${env_name}
    max_episode_steps: 100000

  env_seed: 432
  batch_size: 64
  max_epoch: 100000000

  optimizer:
    classname: torch.optim.Adam
    lr: 0.0001

  epsilon_start: 1.0
  epsilon_final: 0.01
  epsilon_exploration_decay_per_timestep: 30000
  burning_timesteps: 0
  clip_grad: 2
  discount_factor: 0.99
  hard_target_update: True
  update_target_epochs: 1000
  update_target_tau: 0.005
  loss_device: cuda:0
  n_envs: ${n_envs}
  n_processes: ${n_envs}
  n_timesteps: ${n_timesteps}
  overlapping_timesteps: 1
  buffer_size: 100000
  initial_buffer_size: 10000
  buffer_time_size: 2

  evaluation:
    message: "evaluation is needed if using the evaluation version of DQN"
    env_seed: 23
    n_envs: 16
    n_processes: 4
    n_timesteps: 10000

hydra:
  launcher:
    nodes: 1
    mem_gb: 64
    max_num_timeout: 0
    cpus_per_task: 10
    signal_delay_s: 30
    timeout_min: 240
    gpus_per_node: 1
    tasks_per_node: 1
    partition: learnfair
  job_logging:
    root:
      handlers: []

defaults:
  - hydra/launcher: submitit_slurm
